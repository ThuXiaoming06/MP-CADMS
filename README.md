We developed an M-protein Computer-Aided Diagnosis and monitoring System (MP-CADMS) based on deep learning, which employs two modal data of immunofixation electrophoresis (IFE) and structured clinical information (SCI) to achieve the diagnosis and monitoring of M-protein. The SCI involves 2 demographics (age and gender) and 34 test items (sFLC-κ, sFLC-λ, sFLC-κ/λ, α1, α2, Alb%, β1, β2, γ, A/G, F-κ, F-λ, M-Pro, PT, PT%, INR, Fbg, APTT, APTT-R, TT, D-Dimer, Cr(E), Ca, HGB, CK, NT-proBNP, LD, UA, CRP/hsCRP, Alb, 24hUPr, U-Pro, 24hU-V, β2-MG). The diagnosis tasks contain the M-protein presence detection (task 1), isotype classification (task 2) and severity grading. And the monitoring tasks contain the recurrence-recovery prediction (taks 4)and severity-progression prediction (task 5).
Here we release our Python codes for research reading. The code will be improved over time. 

System Requirement
=======
**Software:** The development and validation of MP-CADMS are based on Python 3.10.5 and PyTorch 1.12.0. Data analysis is conducted using libraries NumPy 1.23.1, pandas 1.4.4, matplotlib 3.5.2, SciPy 1.8.1, and scikit-learn 1.1.1.

**Hardtware:** The model training, validation and data analysis are performed using NVIDIA RTX 3060Ti GPUs, 256G RAM, and an Intel Core i7-8700 CPU.

Usage Instructions
=======
- **Pretrain:** The model architecture of IFE extractor employs the self-supervised learning paradigm. In the pretraining stage, both 7,689 unlabeled and 8,943 labeled IFE images are used to train a variational autoencoder (VAE), through completing the pretext task of reconstructing the input iamge pixels. Then the encoder and bottleneck in pretrained VAE are fine-tuned to perform the downstream tasks of diagnosis and monitoring. You can run IFE_pretrain.py (or Pretrain_IFE_extractor.py in Model_Develop folder) to accomplish the pretraining task.

- **M-protein Presence Detection:** For the IFE-modality, the pretrained encoder and bottleneck are used to extract the features. And for the SCI-modality, one-dimensional SCI is first transformred into two-dimensional matrix, where the diagonal elements correspond to the original values, and the non-diagonal elements correspond to the correlation between any two test items. Then a ResNet is employed to extract the features of SCI matrix. Two modal features are fused via several stacked transformer blocks and projected to two probabilities of negative and positive classes. The training and evaluation codes using multimodal and single-modality data are included in Model_Develop folder:
  - **Multimodal diagnosis:** You can run PresDet_Multimodality_train.py to accomplish the training process of negative-positive classifier, and PresDet_Multimodality_eva.py to evaluate the performance of trained classifier.
  - **IFE-modality diagnosis:** You can run PresDet_IFE_train.py to accomplish the training process, and PresDet_IFE_eva.py to evaluate the performance of trained classifier.
  - **SCI-modality diagnosis:** You can run PresDet_SCI_train.py to accomplish the training process, and PresDet_SCI_eva.py to evaluate the performance of trained classifier.  

- **Multitask of Positive-Isotype (PI) Classification and Positive-Severity (PS) Grading:** The extraction and fusion of two modal features are the same as the above description. Since a positive sample possesses both isotype and severity attributes simultaneously, we introduce a multitask learning paradigm to complete the two diagnosis tasks. One branch (PS) projects the fused features into three probabilities corresponding to WP, P(+) and SP(++) classes, while the other branch (PI) projects the fused features into eight probabilities corresponding to IgAκ, IgAλ, IgGκ, IgGλ, IgMκ, IgMλ, κ and λ isotypes. The training and evaluation codes using multimodal and single-modality data are included in Model_Develop folder:
  - **Multimodal diagnosis:** You can run Multitask_Multimodality_train.py to accomplish the training process of multitask classifier, and Multitask_Multimodality_eva.py to evaluate the performance of trained classifier.
  - **IFE-modality diagnosis:** You can run Multitask_IFE_train.py to accomplish the training process, and Multitask_IFE_eva.py to evaluate the performance of trained classifier.
  - **SCI-modality diagnosis:** You can run Multitask_SCI_train.py to accomplish the training process, and Multitask_SCI_eva.py to evaluate the performance of trained classifier.

- **Monitoring:** For a patient's temporal sequence, the extraction and fusion of IFE and SCI features at each time remain consistent with the above description, except that the information of diagnosis labels is also introduced. The three-modality fusion features of all historical time are integrated through a time-aware LSTM. Then the integrated features serve as the initial value conditions of Neural ODE for continuous prediction, including the prediction of recurrence-recovery and severity-progression. The training and evaluation codes are also included in Model_Develop folder: You can run Trans_TSMonitor_train.py to achieve the training process of two nmonitors, and Trans_TSMonitor_eva.py to evaluate the performance of trained monitors.

Data and Results
=======
The datasets from four participating hospitals cannot be shared publicly due to privacy restrictions. Here we released the self-collected (SC) dataset, which is collected from scientific publications (English and Chinese), and various social media platforms. The SC dataset contains 271 images, i.e., 45 negative and 226 positive (25 IgAκ, 28 IgAλ, 66 IgGκ, 39 IgGλ, 27 IgMκ, 14 IgMλ, 9 κ and 18 λ). One can use this dataset for the IFE-modality validation towards presence and PI diagnosis. The expected results can refer to Extended Table 2 in our manuscript.
